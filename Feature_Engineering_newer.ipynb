{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e18e0ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import collections\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ndcg_score\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a683321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Data\n",
    "df = pd.read_csv(\"training_set_VU_DM.csv\")\n",
    "df_test = pd.read_csv(\"test_set_VU_DM.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ae0bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a descriptive dataframe\n",
    "df_descr = pd.concat([df.nunique(), df.isna().sum(), df.notna().sum(), df.dtypes, df.max(), df.min()], axis=1)\n",
    "df_descr.columns = ['Unique values', 'NaN count', 'non NaN count', 'Datatype', 'Max value', 'Min value']\n",
    "df_descr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff71fe4",
   "metadata": {},
   "source": [
    "## Plot Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb75eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "descr2 = df_descr[df_descr['Unique values'] <= 10].index.tolist() # (almost) all are categorical variables\n",
    "descr3 = df_descr[df_descr['Unique values'] > 50].index.tolist() # (almost) all are numerical variables\n",
    "\n",
    "\n",
    "df[descr2].hist(figsize=(16, 20), bins=10, xlabelsize=8, ylabelsize=8)\n",
    "descr3.remove('date_time')\n",
    "descr3.remove('srch_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68834477",
   "metadata": {},
   "source": [
    "## Plot Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3711e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numerical = df[descr3]\n",
    "\n",
    "red_circle = dict(markerfacecolor = 'red', marker = 'o', markeredgecolor = 'white')\n",
    "\n",
    "fig, axs = plt.subplots(11, 2, figsize=(15,25))\n",
    "\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    ax.boxplot(df_numerical.iloc[:,i].dropna(), flierprops = red_circle, vert=False)\n",
    "    ax.set_title(df_numerical.columns[i], fontweight = 'bold')\n",
    "    ax.tick_params(axis = 'y', labelsize = 14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872f954d",
   "metadata": {},
   "source": [
    "## Reduce all comp rate columns to 1 column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226492d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [(df['comp1_rate'].eq(-1) & df['comp1_inv'].ne(1)), \n",
    "              (df['comp2_rate'].eq(-1) & df['comp2_inv'].ne(1)), \n",
    "              (df['comp3_rate'].eq(-1) & df['comp3_inv'].ne(1)),  \n",
    "              (df['comp4_rate'].eq(-1) & df['comp4_inv'].ne(1)), \n",
    "              (df['comp5_rate'].eq(-1) & df['comp5_inv'].ne(1)), \n",
    "              (df['comp6_rate'].eq(-1) & df['comp6_inv'].ne(1)), \n",
    "              (df['comp7_rate'].eq(-1) & df['comp7_inv'].ne(1)),  \n",
    "              (df['comp8_rate'].eq(-1) & df['comp8_inv'].ne(1))]\n",
    "\n",
    "choices = [1,1,1,1,1,1,1,1]\n",
    "print(conditions)\n",
    "\n",
    "df['comp_cheaper'] = np.select(conditions, choices, default=0)\n",
    "\n",
    "# and for test set\n",
    "conditions2 = [(df_test['comp1_rate'].eq(-1) & df_test['comp1_inv'].ne(1)), \n",
    "              (df_test['comp2_rate'].eq(-1) & df_test['comp2_inv'].ne(1)), \n",
    "              (df_test['comp3_rate'].eq(-1) & df_test['comp3_inv'].ne(1)),  \n",
    "              (df_test['comp4_rate'].eq(-1) & df_test['comp4_inv'].ne(1)), \n",
    "              (df_test['comp5_rate'].eq(-1) & df_test['comp5_inv'].ne(1)), \n",
    "              (df_test['comp6_rate'].eq(-1) & df_test['comp6_inv'].ne(1)), \n",
    "              (df_test['comp7_rate'].eq(-1) & df_test['comp7_inv'].ne(1)),  \n",
    "              (df_test['comp8_rate'].eq(-1) & df_test['comp8_inv'].ne(1))]\n",
    "\n",
    "choices2 = [1,1,1,1,1,1,1,1]\n",
    "\n",
    "df_test['comp_cheaper'] = np.select(conditions2, choices2, default=0)\n",
    "df_test['comp_cheaper'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d889130",
   "metadata": {},
   "source": [
    "## Impute columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5cf52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in df.columns:\n",
    "    if c == 'prop_review_score':\n",
    "        df[c] = df[c].fillna(df[c].mode()[0])\n",
    "    elif c == 'prop_location_score2':\n",
    "        df.loc[df.loc[:,c].isnull(),c]=df.loc[:,c].mean()\n",
    "    elif c == 'orig_destination_distance':\n",
    "        df.loc[df.loc[:,c].isnull(),c]=df.loc[:,c].mean()\n",
    "    elif c == 'gross_bookings_usd':\n",
    "        df.loc[df.loc[:,c].isnull(),c]=df.loc[:,c].median()\n",
    "    elif c == 'srch_query_affinity_score':\n",
    "        df.loc[df.loc[:,c].isnull(),c]=df.loc[:,c].median()\n",
    "\n",
    "for c in df_test.columns:\n",
    "    if c == 'prop_review_score':\n",
    "        df_test[c] = df_test[c].fillna(df_test[c].mode()[0])\n",
    "    elif c == 'prop_location_score2':\n",
    "        df_test.loc[df_test.loc[:,c].isnull(),c]=df_test.loc[:,c].mean()\n",
    "    elif c == 'orig_destination_distance':\n",
    "        df_test.loc[df_test.loc[:,c].isnull(),c]=df_test.loc[:,c].mean()\n",
    "    elif c == 'gross_bookings_usd':\n",
    "        df_test.loc[df_test.loc[:,c].isnull(),c]=df_test.loc[:,c].median()\n",
    "    elif c == 'srch_query_affinity_score':\n",
    "        df_test.loc[df_test.loc[:,c].isnull(),c]=df_test.loc[:,c].median()\n",
    "        \n",
    "        \n",
    "\n",
    "print(\"count of NULL values after imputation\\n\")\n",
    "print(df['prop_review_score'].isnull().sum())\n",
    "print(df['prop_location_score2'].isnull().sum())   \n",
    "print(df['gross_bookings_usd'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee96aed2",
   "metadata": {},
   "source": [
    "## Make booleans for starrating and adr_usd (this runtime can still be optimized  - see https://stackoverflow.com/questions/30912403/appending-boolean-column-in-panda-dataframe )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dbb9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "previously_purchased_hotels_train = []\n",
    "for i in df['visitor_hist_starrating'].values:\n",
    "    if i >= 0:\n",
    "        previously_purchased_hotels_train.append(1)\n",
    "    else:\n",
    "        previously_purchased_hotels_train.append(0)\n",
    "        \n",
    "previously_purchased_hotels_test = []\n",
    "\n",
    "for i in df_test['visitor_hist_starrating'].values:\n",
    "    if i >= 0:\n",
    "        previously_purchased_hotels_test.append(1)\n",
    "    else:\n",
    "        previously_purchased_hotels_test.append(0)\n",
    "\n",
    "\n",
    "previously_purchased_hotels_train2 = []\n",
    "for i in df['visitor_hist_adr_usd'].values:\n",
    "    if i >= 0:\n",
    "        previously_purchased_hotels_train2.append(1)\n",
    "    else:\n",
    "        previously_purchased_hotels_train2.append(0)\n",
    "        \n",
    "previously_purchased_hotels_test2 = []\n",
    "\n",
    "for i in df_test['visitor_hist_adr_usd'].values:\n",
    "    if i >= 0:\n",
    "        previously_purchased_hotels_test2.append(1)\n",
    "    else:\n",
    "        previously_purchased_hotels_test2.append(0)\n",
    "        \n",
    "        \n",
    "df.drop('visitor_hist_starrating', inplace = True, axis =1)\n",
    "df.drop('visitor_hist_adr_usd', inplace = True, axis = 1)\n",
    "df_test.drop('visitor_hist_starrating', inplace = True, axis =1)\n",
    "df_test.drop('visitor_hist_adr_usd', inplace = True, axis = 1)\n",
    "df.insert(6, 'visitor_hist_bool', previously_purchased_hotels_train)\n",
    "df_test.insert(6, 'visitor_hist_bool', previously_purchased_hotels_test)\n",
    "df.insert(6, 'visitor_usd_bool', previously_purchased_hotels_train2)\n",
    "df_test.insert(6, 'visitor_usd_bool', previously_purchased_hotels_test2)\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a161c8c3",
   "metadata": {},
   "source": [
    "## Adult ratio added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a88228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For train set\n",
    "adults = df['srch_adults_count'].values\n",
    "children = df['srch_children_count'].values\n",
    "\n",
    "adults = list(adults)\n",
    "children = list(children)\n",
    "\n",
    "ratio_adults = [i/ (i+j) for i, j in zip(adults, children)]\n",
    "\n",
    "df.drop('srch_adults_count', inplace=True, axis=1)\n",
    "df.drop('srch_children_count', inplace=True, axis=1)\n",
    "df.insert(22, 'adult_ratio', ratio_adults)\n",
    "\n",
    "# For test set\n",
    "\n",
    "adults = df_test['srch_adults_count'].values\n",
    "children = df_test['srch_children_count'].values\n",
    "\n",
    "adults = list(adults)\n",
    "children = list(children)\n",
    "\n",
    "ratio_adults = [i/ (i+j) for i, j in zip(adults, children)]\n",
    "\n",
    "df_test.drop('srch_adults_count', inplace=True, axis=1)\n",
    "df_test.drop('srch_children_count', inplace=True, axis=1)\n",
    "df_test.insert(22, 'adult_ratio', ratio_adults)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3997794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the comp rate columns to save storage, as we created new column for this and \n",
    "df = df.drop(['comp1_rate', 'comp1_inv',\n",
    "       'comp1_rate_percent_diff', 'comp2_rate', 'comp2_inv',\n",
    "       'comp2_rate_percent_diff', 'comp3_rate', 'comp3_inv',\n",
    "       'comp3_rate_percent_diff', 'comp4_rate', 'comp4_inv',\n",
    "       'comp4_rate_percent_diff', 'comp5_rate', 'comp5_inv',\n",
    "       'comp5_rate_percent_diff', 'comp6_rate', 'comp6_inv',\n",
    "       'comp6_rate_percent_diff', 'comp7_rate', 'comp7_inv',\n",
    "       'comp7_rate_percent_diff', 'comp8_rate', 'comp8_inv',\n",
    "       'comp8_rate_percent_diff'], axis=1)\n",
    "\n",
    "df_test = df_test.drop(['comp1_rate', 'comp1_inv',\n",
    "       'comp1_rate_percent_diff', 'comp2_rate', 'comp2_inv',\n",
    "       'comp2_rate_percent_diff', 'comp3_rate', 'comp3_inv',\n",
    "       'comp3_rate_percent_diff', 'comp4_rate', 'comp4_inv',\n",
    "       'comp4_rate_percent_diff', 'comp5_rate', 'comp5_inv',\n",
    "       'comp5_rate_percent_diff', 'comp6_rate', 'comp6_inv',\n",
    "       'comp6_rate_percent_diff', 'comp7_rate', 'comp7_inv',\n",
    "       'comp7_rate_percent_diff', 'comp8_rate', 'comp8_inv',\n",
    "       'comp8_rate_percent_diff'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a967fdc",
   "metadata": {},
   "source": [
    "# To do "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9d80b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'visitor_location_country_id'\n",
    "median = df['visitor_location_country_id'].median()\n",
    "df['visitor_location_country_bool'] = np.select([df['visitor_location_country_id'].ge(median)],[1], default=0)\n",
    "median = df_test['visitor_location_country_id'].median()\n",
    "df_test['visitor_location_country_bool'] = np.select([df_test['visitor_location_country_id'].ge(median)],[1], default=0)\n",
    "\n",
    "# 'prop_country_id'\n",
    "median = df['prop_country_id'].median()\n",
    "df['prop_country_bool'] = np.select([df['prop_country_id'].ge(median)],[1], default=0)\n",
    "median = df_test['prop_country_id'].median()\n",
    "df_test['prop_country_bool'] = np.select([df_test['prop_country_id'].ge(median)],[1], default=0)\n",
    "\n",
    "# 'orig_destination_distance'\n",
    "median = df['orig_destination_distance'].median()\n",
    "df['orig_destination_distance_bool'] = np.select([df['orig_destination_distance'].ge(median)],[1], default=0)\n",
    "median = df_test['orig_destination_distance'].median()\n",
    "df_test['orig_destination_distance_bool'] = np.select([df_test['orig_destination_distance'].ge(median)],[1], default=0)\n",
    "\n",
    "# srch_length_of_stay\n",
    "median = df['srch_length_of_stay'].median()\n",
    "df['srch_length_of_stay_bool'] = np.select([df['srch_length_of_stay'].ge(median)],[1], default=0)\n",
    "median = df_test['srch_length_of_stay'].median()\n",
    "df_test['srch_length_of_stay_bool'] = np.select([df_test['srch_length_of_stay'].ge(median)],[1], default=0)\n",
    "\n",
    "# srch_booking_window\n",
    "median = df['srch_booking_window'].median()\n",
    "df['srch_booking_window_bool'] = np.select([df['srch_booking_window'].ge(median)],[1], default=0)\n",
    "median = df_test['srch_booking_window'].median()\n",
    "df_test['srch_booking_window_bool'] = np.select([df_test['srch_booking_window'].ge(median)],[1], default=0)\n",
    "\n",
    "# df['prop_country_popular'].hist()\n",
    "# len(df[df['srch_length_of_stay_bool']==1])\n",
    "\n",
    "# 'visitor_location_country_id' + 'prop_country_id'  - splitten in boolean: 200 of hoger / lager dan 200\n",
    "# 'orig_destination_distance' (386 meadiaan) , 'srch_length_of_stay' (2 mediaan), 'srch_booking_window' (mediaan 17) -  opsplitsen in 2 categorieen \n",
    "# 'prop_location_score1' , 'prop_review_score', \"prop_log_historical_price\", 'srch_query_affinity_score',  normalize between 0 and 1 (min/max)\n",
    "# 'price_usd' / - log normalize and bin  \n",
    "# \n",
    "# check for one hot encoding  - pd.get_dummies \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095a0b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop prop id / srch_destination_id\n",
    "df = df.drop(['srch_destination_id'], axis=1)\n",
    "df_test = df_test.drop(['srch_destination_id'], axis=1)\n",
    "\n",
    "# drop old columns\n",
    "df = df.drop(['visitor_location_country_id', 'prop_country_id',\n",
    "       'orig_destination_distance', 'srch_length_of_stay', 'srch_booking_window'], axis=1)\n",
    "\n",
    "df_test = df_test.drop(['visitor_location_country_id', 'prop_country_id',\n",
    "       'orig_destination_distance', 'srch_length_of_stay', 'srch_booking_window'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc429fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   normalize between 0 and 1 (min/max) 'prop_location_score1','prop_review_score',\"prop_log_historical_price\",'srch_query_affinity_score'\n",
    "def NormalizeData(data):\n",
    "    return (data - np.min(data)) / (np.max(data) - np.min(data))\n",
    "df['prop_location_score1'] = NormalizeData(df['prop_location_score1'])\n",
    "df['prop_review_score'] = NormalizeData(df['prop_review_score'])\n",
    "df['prop_log_historical_price'] = NormalizeData(df['prop_log_historical_price'])\n",
    "df['srch_query_affinity_score'] = NormalizeData(df['srch_query_affinity_score'])\n",
    "\n",
    "\n",
    "df_test['prop_location_score1'] = NormalizeData(df_test['prop_location_score1'])\n",
    "df_test['prop_review_score'] = NormalizeData(df_test['prop_review_score'])\n",
    "df_test['prop_log_historical_price'] = NormalizeData(df_test['prop_log_historical_price'])\n",
    "df_test['srch_query_affinity_score'] = NormalizeData(df_test['srch_query_affinity_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ba5763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# made price into categorical data\n",
    "df['price_usd'] = df['price_usd'].transform(lambda x: np.log(x + 1))\n",
    "df['price_usd'] = NormalizeData(df['price_usd']) # dit is overbodig\n",
    "quantile02 = df['price_usd'].quantile(0.2)\n",
    "quantile04 = df['price_usd'].quantile(0.4)\n",
    "quantile06 = df['price_usd'].quantile(0.6)\n",
    "quantile08 = df['price_usd'].quantile(0.8)\n",
    "\n",
    "conditionsprice = [(df['price_usd'].ge(quantile02) & df['price_usd'].lt(quantile04)), \n",
    "              (df['price_usd'].ge(quantile04) & df['price_usd'].lt(quantile06)), \n",
    "              (df['price_usd'].ge(quantile06) & df['price_usd'].lt(quantile08)),  \n",
    "              (df['price_usd'].ge(quantile08)) \n",
    "              ]\n",
    "\n",
    "choicesprice = [1,2,3,4,]\n",
    "\n",
    "df['price_usd'] = np.select(conditionsprice, choicesprice, default=0)\n",
    "df['price_usd'].hist()\n",
    "\n",
    "\n",
    "# made price into categorical data\n",
    "df_test['price_usd'] = df_test['price_usd'].transform(lambda x: np.log(x + 1))\n",
    "df_test['price_usd'] = NormalizeData(df_test['price_usd']) # dit is overbodig\n",
    "quantile02 = df_test['price_usd'].quantile(0.2)\n",
    "quantile04 = df_test['price_usd'].quantile(0.4)\n",
    "quantile06 = df_test['price_usd'].quantile(0.6)\n",
    "quantile08 = df_test['price_usd'].quantile(0.8)\n",
    "\n",
    "conditionsprice = [(df_test['price_usd'].ge(quantile02) & df_test['price_usd'].lt(quantile04)), \n",
    "              (df_test['price_usd'].ge(quantile04) & df_test['price_usd'].lt(quantile06)), \n",
    "              (df_test['price_usd'].ge(quantile06) & df_test['price_usd'].lt(quantile08)),  \n",
    "              (df_test['price_usd'].ge(quantile08)) \n",
    "              ]\n",
    "\n",
    "choicesprice = [1,2,3,4,]\n",
    "\n",
    "df_test['price_usd'] = np.select(conditionsprice, choicesprice, default=0)\n",
    "df_test['price_usd'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2641475",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df.columns)\n",
    "\n",
    "df_descr_two = pd.concat([df.nunique(), df.isna().sum(), df.notna().sum(), df.dtypes, df.max(), df.min()], axis=1)\n",
    "df_descr_two.columns = ['Unique values', 'NaN count', 'non NaN count', 'Datatype', 'Max value', 'Min value']\n",
    "df_descr_two\n",
    "\n",
    "#df['srch_booking_window'].hist()\n",
    "# df_descr_two\n",
    "# srch_length_of_stay , srch_booking_window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdeaae4f",
   "metadata": {},
   "source": [
    "#  ----------------------------------XGBoost------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "181ae021",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check X_train / X_val if all new created features are incorporated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "00ff4020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2978462, 22) (1979885, 22)\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Make training and validation split - based on search id\n",
    "\n",
    "# we exclude the columns that are not in the test set\n",
    "# Exclude prop _id because to many categories\n",
    "\n",
    "df1 = df[df['srch_id']<= 200000]\n",
    "df2 = df[df['srch_id']> 200000]\n",
    "\n",
    "X_train = df1.loc[:, df1.columns.isin(['site_id', 'visitor_location_country_bool',\n",
    "       'prop_country_bool', 'visitor_hist_bool', 'prop_starrating',\n",
    "       'prop_review_score', 'prop_brand_bool', 'prop_location_score1',\n",
    "       'prop_location_score2', 'prop_log_historical_price', 'visitor_hist_bool', \n",
    "        'visitor_usd_bool', 'price_usd', 'promotion_flag',\n",
    "       'srch_length_of_stay_bool', 'srch_booking_window_bool', 'srch_room_count',\n",
    "       'srch_saturday_night_bool', 'srch_query_affinity_score', 'adult_ratio',\n",
    "       'orig_destination_distance_bool', 'random_bool', 'comp_cheaper'])]\n",
    "y_train = df1.loc[:, df1.columns.isin(['booking_bool'])]\n",
    "\n",
    "X_val = df2.loc[:, df2.columns.isin(['site_id', 'visitor_location_country_bool',\n",
    "       'prop_country_bool', 'visitor_hist_bool', 'prop_starrating',\n",
    "       'prop_review_score', 'prop_brand_bool', 'prop_location_score1',\n",
    "       'prop_location_score2', 'prop_log_historical_price', 'visitor_hist_bool', \n",
    "        'visitor_usd_bool', 'price_usd', 'promotion_flag',\n",
    "       'srch_length_of_stay_bool', 'srch_booking_window_bool', 'srch_room_count',\n",
    "       'srch_saturday_night_bool', 'srch_query_affinity_score', 'adult_ratio',\n",
    "       'orig_destination_distance_bool', 'random_bool', 'comp_cheaper'])]\n",
    "y_val = df2.loc[:, df2.columns.isin(['booking_bool'])]\n",
    "\n",
    "print(X_train.shape, X_val.shape)\n",
    "# Set some features to type category to help xgboost\n",
    "X_train[['site_id','visitor_location_country_bool','prop_review_score',\n",
    "       'prop_country_bool', 'prop_starrating', 'prop_brand_bool', 'promotion_flag',\n",
    "         'visitor_hist_bool', 'visitor_usd_bool','srch_length_of_stay_bool', 'srch_booking_window_bool', 'srch_room_count', \n",
    "         'srch_saturday_night_bool', 'random_bool']].astype(\"category\")\n",
    "X_val[['site_id','visitor_location_country_bool','prop_review_score',\n",
    "       'prop_country_bool', 'prop_starrating', 'prop_brand_bool', 'promotion_flag',\n",
    "         'visitor_hist_bool', 'visitor_usd_bool','srch_length_of_stay_bool', 'srch_booking_window_bool', 'srch_room_count', \n",
    "         'srch_saturday_night_bool', 'random_bool']].astype(\"category\")\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "38e52110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=True,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit and train the model\n",
    "clf2 = xgb.XGBClassifier(tree_method=\"approx\", enable_categorical=True, use_label_encoder=False)\n",
    "clf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "bccde21f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['site_id' 'visitor_usd_bool' 'visitor_hist_bool' 'prop_starrating'\n",
      " 'prop_review_score' 'prop_brand_bool' 'prop_location_score1'\n",
      " 'prop_location_score2' 'prop_log_historical_price' 'price_usd'\n",
      " 'promotion_flag' 'srch_room_count' 'srch_saturday_night_bool'\n",
      " 'adult_ratio' 'srch_query_affinity_score' 'random_bool' 'comp_cheaper'\n",
      " 'visitor_location_country_bool' 'prop_country_bool'\n",
      " 'orig_destination_distance_bool' 'srch_length_of_stay_bool'\n",
      " 'srch_booking_window_bool']\n",
      "[0.00730816 0.00693717 0.01057633 0.02633808 0.01556457 0.01185575\n",
      " 0.03041524 0.04265395 0.00923215 0.01525085 0.04361676 0.01549068\n",
      " 0.0056587  0.01465357 0.00670408 0.669785   0.01375756 0.00799165\n",
      " 0.0132435  0.01099659 0.01061512 0.01135443]\n",
      "Accuracy Training:  0.9722114970746647\n",
      "Booked or not: [0 1]\n",
      "Probabilities of being booked: [0.00818393 0.00527882 0.00330212 ... 0.02544005 0.00526438 0.02885399]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wiebe\\AppData\\Local\\Temp\\ipykernel_1940\\33990949.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train_result['booking_pred_prob'] = XGB_prob[:,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srch_id</th>\n",
       "      <th>prop_id</th>\n",
       "      <th>position</th>\n",
       "      <th>booking_bool</th>\n",
       "      <th>booking_pred_prob</th>\n",
       "      <th>position_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>88218</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019173</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>53341</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.018630</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>95307</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015923</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>88096</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014105</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>29604</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014024</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2978449</th>\n",
       "      <td>200000</td>\n",
       "      <td>94042</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008301</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2978453</th>\n",
       "      <td>200000</td>\n",
       "      <td>99540</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007853</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2978452</th>\n",
       "      <td>200000</td>\n",
       "      <td>98034</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007295</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2978460</th>\n",
       "      <td>200000</td>\n",
       "      <td>132353</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005264</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2978439</th>\n",
       "      <td>200000</td>\n",
       "      <td>39895</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005234</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2978462 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         srch_id  prop_id  position  booking_bool  booking_pred_prob  \\\n",
       "18             1    88218         8             0           0.019173   \n",
       "8              1    53341         3             0           0.018630   \n",
       "21             1    95307         1             0           0.015923   \n",
       "16             1    88096        23             0           0.014105   \n",
       "4              1    29604         4             0           0.014024   \n",
       "...          ...      ...       ...           ...                ...   \n",
       "2978449   200000    94042        29             0           0.008301   \n",
       "2978453   200000    99540         3             0           0.007853   \n",
       "2978452   200000    98034         9             0           0.007295   \n",
       "2978460   200000   132353        32             0           0.005264   \n",
       "2978439   200000    39895        34             0           0.005234   \n",
       "\n",
       "         position_rank  \n",
       "18                 1.0  \n",
       "8                  2.0  \n",
       "21                 3.0  \n",
       "16                 4.0  \n",
       "4                  5.0  \n",
       "...                ...  \n",
       "2978449           26.0  \n",
       "2978453           27.0  \n",
       "2978452           28.0  \n",
       "2978460           29.0  \n",
       "2978439           30.0  \n",
       "\n",
       "[2978462 rows x 6 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score the training data\n",
    "print(clf2.feature_names_in_)\n",
    "print(clf2.feature_importances_)\n",
    "score = clf2.score(X_train, y_train, sample_weight=None)\n",
    "print('Accuracy Training: ', score)\n",
    "XGB_prob = clf2.predict_proba(X_train)\n",
    "print(\"Booked or not:\", clf2.classes_)\n",
    "print(\"Probabilities of being booked:\", XGB_prob[:,1])\n",
    "df_train_result = df1.loc[:, df1.columns.isin(['srch_id', 'prop_id', 'booking_bool', 'position'])]\n",
    "df_train_result['booking_pred_prob'] = XGB_prob[:,1]\n",
    "df_sorted_train = df_train_result.sort_values([\"srch_id\", \"booking_pred_prob\"], ascending=[True, False])\n",
    "df_sorted_train[['srch_id', 'prop_id', \"booking_pred_prob\", 'booking_bool', 'position']]\n",
    "df_sorted_train['position_rank'] = df_sorted_train.groupby('srch_id')['booking_pred_prob'].rank(ascending=False)\n",
    "df_sorted_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d62880e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average NDCG for all users in training set is:  0.8914695745776796\n"
     ]
    }
   ],
   "source": [
    "# Calculate NDCG\n",
    "grouped = df_sorted_train.groupby('srch_id')\n",
    "\n",
    "def ndcg(group):\n",
    "    y_pred = group[\"position_rank\"].values # predicted rank\n",
    "    y_true = group[\"position\"].values # true rank\n",
    "    y_pred = [y_pred]\n",
    "    y_true = [y_true]\n",
    "    return ndcg_score(y_true, y_pred)\n",
    "\n",
    "ndcg_list = grouped.apply(ndcg)\n",
    "print('Average NDCG for all users in training set is: ', ndcg_list.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c4693db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Validation:  0.9720160514373309\n",
      "Booked or not: [0 1]\n",
      "Probabilities of being booked: [0.002019   0.01370149 0.00592883 ... 0.02400131 0.03828261 0.0195649 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wiebe\\AppData\\Local\\Temp\\ipykernel_1940\\873917198.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val_result['booking_pred_prob'] = XGB_prob[:,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srch_id</th>\n",
       "      <th>prop_id</th>\n",
       "      <th>position</th>\n",
       "      <th>booking_bool</th>\n",
       "      <th>booking_pred_prob</th>\n",
       "      <th>position_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4958322</th>\n",
       "      <td>332784</td>\n",
       "      <td>48216</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011217</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4958343</th>\n",
       "      <td>332785</td>\n",
       "      <td>88083</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.091153</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4958345</th>\n",
       "      <td>332785</td>\n",
       "      <td>128360</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.038283</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4958342</th>\n",
       "      <td>332785</td>\n",
       "      <td>77700</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.033422</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4958344</th>\n",
       "      <td>332785</td>\n",
       "      <td>94508</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024001</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4958346</th>\n",
       "      <td>332785</td>\n",
       "      <td>134949</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019565</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4958341</th>\n",
       "      <td>332785</td>\n",
       "      <td>55110</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009393</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         srch_id  prop_id  position  booking_bool  booking_pred_prob  \\\n",
       "4958322   332784    48216        22             0           0.011217   \n",
       "4958343   332785    88083         3             0           0.091153   \n",
       "4958345   332785   128360         1             1           0.038283   \n",
       "4958342   332785    77700         2             0           0.033422   \n",
       "4958344   332785    94508         4             0           0.024001   \n",
       "4958346   332785   134949         6             0           0.019565   \n",
       "4958341   332785    55110         7             0           0.009393   \n",
       "\n",
       "         position_rank  \n",
       "4958322           28.0  \n",
       "4958343            1.0  \n",
       "4958345            2.0  \n",
       "4958342            3.0  \n",
       "4958344            4.0  \n",
       "4958346            5.0  \n",
       "4958341            6.0  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score the validation data\n",
    "score = clf2.score(X_val, y_val, sample_weight=None)\n",
    "print('Accuracy Validation: ', score)\n",
    "XGB_prob = clf2.predict_proba(X_val)\n",
    "print(\"Booked or not:\", clf2.classes_)\n",
    "print(\"Probabilities of being booked:\", XGB_prob[:,1])\n",
    "df_val_result = df2.loc[:, df2.columns.isin(['srch_id', 'prop_id', 'booking_bool', 'position'])]\n",
    "df_val_result['booking_pred_prob'] = XGB_prob[:,1]\n",
    "df_sorted_val = df_val_result.sort_values([\"srch_id\", \"booking_pred_prob\"], ascending=[True, False])\n",
    "df_sorted_val[['srch_id', 'prop_id', \"booking_pred_prob\",'booking_bool', 'position']]\n",
    "df_sorted_val['position_rank'] = df_sorted_val.groupby('srch_id')['booking_pred_prob'].rank(ascending=False)\n",
    "df_sorted_val.tail(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "08db1286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average NDCG for all users in val set is:  0.7277754446524305\n"
     ]
    }
   ],
   "source": [
    "# Calculate NDCG\n",
    "grouped = df_sorted_val.groupby('srch_id')\n",
    "\n",
    "def ndcg(group):\n",
    "    y_pred = group[\"position_rank\"].values # predicted rank\n",
    "    y_true = group[\"position\"].values # true rank\n",
    "    y_pred = [y_pred]\n",
    "    y_true = [y_true]\n",
    "    return ndcg_score(y_true, y_pred, k=5)\n",
    "\n",
    "ndcg_list = grouped.apply(ndcg)\n",
    "print('Average NDCG for all users in val set is: ', ndcg_list.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4df3ce",
   "metadata": {},
   "source": [
    "# Run test csv for kaggle submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d4e0345e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wiebe\\AppData\\Local\\Temp\\ipykernel_1940\\1107206340.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test_result['booking_pred_prob'] = XGB_prob_t[:,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srch_id</th>\n",
       "      <th>prop_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>99484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>50162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>54937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>128085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>61934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959176</th>\n",
       "      <td>332787</td>\n",
       "      <td>22854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959178</th>\n",
       "      <td>332787</td>\n",
       "      <td>32019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959182</th>\n",
       "      <td>332787</td>\n",
       "      <td>99509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959181</th>\n",
       "      <td>332787</td>\n",
       "      <td>94437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959180</th>\n",
       "      <td>332787</td>\n",
       "      <td>35240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4959183 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         srch_id  prop_id\n",
       "23             1    99484\n",
       "8              1    50162\n",
       "9              1    54937\n",
       "25             1   128085\n",
       "12             1    61934\n",
       "...          ...      ...\n",
       "4959176   332787    22854\n",
       "4959178   332787    32019\n",
       "4959182   332787    99509\n",
       "4959181   332787    94437\n",
       "4959180   332787    35240\n",
       "\n",
       "[4959183 rows x 2 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Now for test csv\n",
    "X_test = df_test.loc[:, df_test.columns.isin(['site_id', 'visitor_location_country_bool',\n",
    "       'prop_country_bool', 'visitor_hist_bool', 'prop_starrating',\n",
    "       'prop_review_score', 'prop_brand_bool', 'prop_location_score1',\n",
    "       'prop_location_score2', 'prop_log_historical_price', 'visitor_hist_bool', \n",
    "        'visitor_usd_bool', 'price_usd', 'promotion_flag',\n",
    "       'srch_length_of_stay_bool', 'srch_booking_window_bool', 'srch_room_count',\n",
    "       'srch_saturday_night_bool', 'srch_query_affinity_score', 'adult_ratio',\n",
    "       'orig_destination_distance_bool', 'random_bool', 'comp_cheaper'])]\n",
    "\n",
    "X_test[['site_id','visitor_location_country_bool','prop_review_score',\n",
    "       'prop_country_bool', 'prop_starrating', 'prop_brand_bool', 'promotion_flag',\n",
    "         'visitor_hist_bool', 'visitor_usd_bool','srch_length_of_stay_bool', 'srch_booking_window_bool', 'srch_room_count', \n",
    "         'srch_saturday_night_bool', 'random_bool']].astype(\"category\")\n",
    "\n",
    "\n",
    "XGB_prob_t = clf2.predict_proba(X_test)\n",
    "#print(NB_prob_t[:,1]) # Probabilities of being booked\n",
    "\n",
    "df_test_result = df_test[['srch_id', 'prop_id']]\n",
    "df_test_result['booking_pred_prob'] = XGB_prob_t[:,1]\n",
    "df_sorted = df_test_result.sort_values([\"srch_id\", \"booking_pred_prob\"], ascending=[True, False])\n",
    "final_frame = df_sorted[['srch_id', 'prop_id']]\n",
    "#final_frame\n",
    "# header \"SearchId ,PropertyId\" \n",
    "final_frame.to_csv('xgb_group93_model2.csv', index=False)\n",
    "final_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a16dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do : tuning -> https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48865c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random guessing for benchmarking\n",
    "# Lasso ?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
